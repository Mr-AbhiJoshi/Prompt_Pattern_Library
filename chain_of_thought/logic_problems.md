# ğŸ” Prompt Pattern: Chain of Thought (CoT)

## ğŸ§ª Use Case: Solving Logic Problems

## Case 1 (Truth-teller and liar problem)

### ğŸ“ Prompt Used

You are a reasoning assistant that solves logic puzzles step by step.

Question: You meet two people: Alice and Bob. One of them always tells the truth, the other always lies.

Alice says, "Bob is the liar."  
Bob says, "We are both liars."

Who is the truth-teller?

### ğŸ¤– Model Output

Letâ€™s reason through this:

Step 1: Bob says, â€œWe are both liars.â€ If Bob were telling the truth, then they would both be liars. But a truth-teller canâ€™t claim to be a liar â€” thatâ€™s a contradiction.

Step 2: So Bob must be lying.

Step 3: That means his statement "We are both liars" is false. Therefore, itâ€™s not true that both are liars â†’ which implies one of them is telling the truth.

Step 4: Alice says, â€œBob is the liar.â€ Since Bob is the liar, Alice must be telling the truth.

âœ… Final Answer: Alice is the truth-teller.

---

## Case 2 (Logical deduction â€“ identifying the criminal)

### ğŸ“ Prompt Used

You are a logic puzzle solver. Work step by step.

Question: Three suspects â€” Anna, Brian, and Clara â€” are questioned.

- Anna says: â€œI didnâ€™t do it. Brian did it.â€
- Brian says: â€œI didnâ€™t do it.â€
- Clara says: â€œAnna did it.â€

Only one person is telling the truth. Who committed the crime?

### ğŸ¤– Model Output

Letâ€™s test each suspect as the possible truth-teller.

Option 1: Anna is telling the truth

â†’ â€œI didnâ€™t do it. Brian did it.â€

â†’ That means Brian is guilty.

â†’ Brian says â€œI didnâ€™t do itâ€ â†’ this would be a lie.

â†’ Clara says â€œAnna did itâ€ â†’ also a lie.

âœ… This setup works. Only Anna is telling the truth.

Option 2: Brian is telling the truth

â†’ â€œI didnâ€™t do itâ€

â†’ Then Anna is lying â†’ she did it or Brian didnâ€™t do it.

â†’ Clara says Anna did it â†’ would be true, but now two people (Brian and Clara) are telling the truth â†’ contradiction.

Option 3: Clara is telling the truth

â†’ â€œAnna did itâ€
â†’ Then Anna is lying â†’ she did it or Brian didnâ€™t.

â†’ Brian says â€œI didnâ€™t do itâ€ â†’ true â†’ again two people are truthful â†’ contradiction.

âœ… Final Answer: Brian committed the crime. Anna is the only one telling the truth.

---

## **Important** Case 3 (Seating arrangement logic)

#### Note: In this example, we will see, how sometimes model just starts to hallucinate and provide contradictory answers.

### ğŸ“ Prompt Attempt 1

You are a step-by-step logic assistant.

Question: Four friends (Alex, Blake, Chris, Dana) are sitting in a row.

- Alex is not at either end.
- Dana is to the right of Chris.
- Blake is not next to Dana.

In what order are they sitting (left to right)?

### ğŸ¤– Model Output

Letâ€™s go step by step.

Step 1: There are 4 positions: [ _ , _ , _ , _ ]

Step 2: "Alex is not at either end" â†’ so Alex is in position 2 or 3.

Step 3: "Dana is to the right of Chris" â†’ Dana must be seated after Chris (i.e., higher index).

Step 4: "Blake is not next to Dana" â†’ Blake can't be immediately adjacent to Dana.

Letâ€™s try placing Chris at position 1:

Chris at 1 â†’ Dana must be at 2, 3, or 4 (right of Chris)

Try Dana at 3

â†’ Alex can go at 2 (valid)

â†’ That leaves Blake at 4

But now: Dana (3), Blake (4) â†’ they are next to each other â†’ âŒ violates "Blake not next to Dana"

Try Dana at position 4: Chris at 1, Dana at 4

Alex at 2 â†’ valid

Blake at 3 â†’ now Blake is next to Dana â†’ âŒ violates constraint again.

Try Dana at 3: Chris at 1, Dana at 3, Alex at 2, Blake at 4 â†’ Dana and Blake again adjacent â†’ âŒ

Try Dana at 2:

Chris at 1

Dana at 2 â†’ Blake cannot be at 1 or 3 â†’ stuck.

Now try Chris at position 2, Dana at 3:

Chris at 2

Dana at 3 â†’ satisfies â€œDana is to the right of Chrisâ€

Alex must be at 2 or 3 â†’ both taken
â†’ So Alex goes at position 4 â†’ âŒ violates "not at ends"

Eventually, try:

Chris at 1

Alex at 2

Dana at 4

Blake at 3 â†’ Blake and Dana are not adjacent â†’ âœ… valid

âœ… Final Answer: [Chris, Alex, Blake, Dana]

#### See, how even though we had mentioned Blake is not next to Dana, the model has chosen to ignore it, and just provide us with a made-up answer. Now, to correct it, we will ask it to explain it's reasoning for steps.

### ğŸ“ Prompt Attempt 2

Try solving this problem again. Explain your reasoning at each step.

You are a step-by-step logic assistant.

Question: Four friends (Alex, Blake, Chris, Dana) are sitting in a row.

- Alex is not at either end.
- Dana is to the right of Chris.
- Blake is not next to Dana.

In what order are they sitting (left to right)?

### ğŸ¤– Model Output

ğŸ§© Problem: We have 4 friends: Alex, Blake, Chris, Dana. They are sitting in a row of 4 seats (left to right), and we are given three constraints:

Alex is not at either end. â†’ So Alex can only be in position 2 or 3.

Dana is to the right of Chris. â†’ Dana must sit in a higher-numbered seat than Chris.

Blake is not next to Dana. â†’ They cannot be adjacent.

âœ… Step-by-step Reasoning

Letâ€™s represent the 4 positions as:

[ _, _, _, _ ] â†’ Positions 1, 2, 3, 4 (left to right)

Letâ€™s now iterate through valid placements of Alex (since constraint #1 limits her positions).

ğŸ” Try placing Alex at position 2:

Current: [ _, Alex, _, _ ]

Remaining people: Blake, Chris, Dana

Letâ€™s now try assigning Chris and Dana in a way that satisfies â€œDana is to the right of Chrisâ€.

Try: Chris at 1, Dana at 3

Now we have: [Chris, Alex, Dana, _]

Remaining: Blake â†’ must go at position 4

Final: [Chris, Alex, Dana, Blake]

Now validate all constraints:

âœ… Alex is not at either end â†’ position 2 âœ…

âœ… Dana is to the right of Chris (Chris at 1, Dana at 3) âœ…

âŒ Blake is next to Dana (positions 3 and 4) â†’ violates constraint

Try a different configuration.

ğŸ” Keep Alex at position 2, but try Dana at 4 and Chris at 1:

Now: [Chris, Alex, _, Dana]

Remaining: Blake â†’ only position 3

Final: [Chris, Alex, Blake, Dana]

Check constraints:

âœ… Alex not at either end â†’ position 2 âœ…

âœ… Dana (4) is to the right of Chris (1) âœ…

âœ… Blake (3) is not next to Dana (4) âŒ â†’ actually, they are adjacent â†’ violates constraint

ğŸ” Try Alex at position 3 instead:

Current: [ _, _, Alex, _ ]

Available: 1, 2, 4

Try placing Chris at 1, Dana at 2 â†’ Dana is not to the right of Chris â†’ âŒ

Try Chris at 1, Dana at 4:

Now: [Chris, _, Alex, Dana]

Remaining: Blake â†’ only position 2

Final: [Chris, Blake, Alex, Dana]

Check:

âœ… Alex not at ends â†’ position 3 âœ…

âœ… Dana (4) is to the right of Chris (1) âœ…

âœ… Blake (2) is not next to Dana (4) â†’ Dana is at 4, Blake at 2 â†’ not adjacent âœ…

âœ… All constraints satisfied!

ğŸ§¾ Final Answer: [Chris, Blake, Alex, Dana]

---

### ğŸ§  Observations

Chain of Thought prompting helped unpack complex conditions and conflicting constraints.

The model could simulate multiple scenarios, reject invalid ones, and converge on the correct solution.

This systematic approach avoids guessing and mirrors how a human would reason through logic puzzles.

---

## ğŸ’¡ Reflections

CoT is a powerful tool for logic-based problems involving deduction, elimination, and simulation of outcomes.

It encourages hypothesis testing and constraint satisfactionâ€”core strategies in logical reasoning.

When faced with puzzles, conflicting statements, or multi-step inferences, CoT helps the model â€œthink out loud.â€

Combining CoT with a directive like â€œevaluate all possibilitiesâ€ or â€œeliminate contradictionsâ€ can yield highly reliable results.